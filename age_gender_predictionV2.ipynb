{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Project Checklist\n",
    "1. Frame the problem and look at the bigger picture\n",
    "2. Get the data\n",
    "3. Explore the data to gain insights\n",
    "4. Prepare the data to better expose the underlying data patterns to machine learning algorithms\n",
    "5. Explore many different models and shortlist the best ones\n",
    "6. Fine-tune yor models and combine them into a greate solution\n",
    "7. present your solution\n",
    "8. Launch, monitor and maintain your system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing the data from Kaggle using kagglehub\n",
    "import kagglehub\n",
    "\n",
    "# Download and get the path to the UTKFace dataset\n",
    "path = kagglehub.dataset_download(\"jangedoo/utkface-new\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "path = os.path.join(path, \"UTKFace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set target image size and other parameters\n",
    "IMG_HEIGHT, IMG_WIDTH = 128, 128  # You can change these dimensions as needed\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10  # Adjust epochs depending on your dataset and GPU/CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize lists to hold image data and labels\n",
    "images = []\n",
    "ages = []\n",
    "genders = []\n",
    "\n",
    "# Loop over each file in the dataset folder\n",
    "for filename in os.listdir(path):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        # The filename format is usually: age_gender_race_date.jpg\n",
    "        try:\n",
    "            parts = filename.split('_')\n",
    "            age = int(parts[0])\n",
    "            gender = int(parts[1])  # Typically 0 for male and 1 for female\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping file {filename} due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Load image with the specified target size\n",
    "        img_path = os.path.join(path, filename)\n",
    "        img = load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "        img = img_to_array(img)\n",
    "        images.append(img)\n",
    "        ages.append(age)\n",
    "        genders.append(gender)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "images = np.array(images, dtype=\"float32\")\n",
    "ages = np.array(ages, dtype=\"float32\")\n",
    "genders = np.array(genders, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shapes:\n",
      "Images: (23708, 128, 128, 3)\n",
      "Ages: (23708,)\n",
      "Genders: (23708,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Normalize the image pixel values to [0, 1]\n",
    "images /= 255.0\n",
    "\n",
    "print(\"Dataset shapes:\")\n",
    "print(\"Images:\", images.shape)\n",
    "print(\"Ages:\", ages.shape)\n",
    "print(\"Genders:\", genders.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_age_train, y_age_test, y_gender_train, y_gender_test = train_test_split(\n",
    "    images, ages, genders, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 128, 128, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 128, 128, 32  128        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 64, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 64, 64, 64)   18496       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 64)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 128)  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 128)  0          ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 16, 16, 256)  295168      ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 256)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 8, 8, 256)    590080      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 256)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 4096)         0           ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          2097664     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          65664       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          65664       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 128)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " age (Dense)                    (None, 1)            129         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " gender (Dense)                 (None, 1)            129         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,210,690\n",
      "Trainable params: 3,209,218\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build the multi-output model using the Functional API\n",
    "input_layer = keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "# Shared convolutional base\n",
    "# Convolutional base with BatchNormalization and additional filters\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Age regression branch\n",
    "age_branch = layers.Dense(128, activation='relu')(x)\n",
    "age_branch = layers.Dropout(0.5)(age_branch)\n",
    "age_output = layers.Dense(1, name='age')(age_branch)\n",
    "\n",
    "# Gender classification branch\n",
    "gender_branch = layers.Dense(128, activation='relu')(x)\n",
    "gender_branch = layers.Dropout(0.5)(gender_branch)\n",
    "gender_output = layers.Dense(1, activation='sigmoid', name='gender')(gender_branch)\n",
    "\n",
    "# Create the model with two outputs\n",
    "model = keras.Model(inputs=input_layer, outputs=[age_output, gender_output])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "297/297 [==============================] - 22s 59ms/step - loss: 293.1034 - age_loss: 292.1107 - gender_loss: 0.9926 - age_mae: 12.8117 - gender_accuracy: 0.5842 - val_loss: 277.7584 - val_age_loss: 277.0777 - val_gender_loss: 0.6806 - val_age_mae: 13.0278 - val_gender_accuracy: 0.5325\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/model/batch_normalization/FusedBatchNormGradV3' defined at (most recent call last):\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ziadt\\AppData\\Local\\Temp\\ipykernel_16576\\3762816570.py\", line 9, in <module>\n      history = model.fit(\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/batch_normalization/FusedBatchNormGradV3'\nOOM when allocating tensor with shape[64,32,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/batch_normalization/FusedBatchNormGradV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2542]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      3\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     loss\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m},\n\u001b[0;32m      5\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_age_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgender\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_gender_train\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_age_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgender\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_gender_test\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model/batch_normalization/FusedBatchNormGradV3' defined at (most recent call last):\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ziadt\\AppData\\Local\\Temp\\ipykernel_16576\\3762816570.py\", line 9, in <module>\n      history = model.fit(\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"c:\\Users\\ziadt\\anaconda3\\envs\\CV_masterclass_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model/batch_normalization/FusedBatchNormGradV3'\nOOM when allocating tensor with shape[64,32,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/batch_normalization/FusedBatchNormGradV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2542]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compile the model with different loss functions for each output\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'age': 'mse', 'gender': 'binary_crossentropy'},\n",
    "    metrics={'age': 'mae', 'gender': 'accuracy'}\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    {'age': y_age_train, 'gender': y_gender_train},\n",
    "    validation_data=(X_test, {'age': y_age_test, 'gender': y_gender_test}),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history for age and gender losses\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Age loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['age_loss'], label='Train Age Loss')\n",
    "plt.plot(history.history['val_age_loss'], label='Val Age Loss')\n",
    "plt.title('Age Regression Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Gender loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['gender_loss'], label='Train Gender Loss')\n",
    "plt.plot(history.history['val_gender_loss'], label='Val Gender Loss')\n",
    "plt.title('Gender Classification Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Binary Crossentropy Loss')\n",
    "plt.legend()\n",
    "\n",
    "# age accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['age_mae'], label='Train Age MAE')\n",
    "plt.plot(history.history['val_age_mae'], label='Val Age MAE')\n",
    "plt.title('Age Regression MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "# gender accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['gender_accuracy'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Define the directory containing the test images\n",
    "test_images_dir = \"C:/Users/ziadt/Desktop/Projects/syed assignment/SyedAssign/Zezoo/test images\"\n",
    "\n",
    "# List all image files in the directory (adjust extensions as needed)\n",
    "image_files = [os.path.join(test_images_dir, f) \n",
    "               for f in os.listdir(test_images_dir) \n",
    "               if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "print(f\"Found {len(image_files)} images for prediction.\")\n",
    "\n",
    "# Define grid layout for displaying images\n",
    "n_cols = 3\n",
    "n_rows = (len(image_files) + n_cols - 1) // n_cols\n",
    "plt.figure(figsize=(n_cols * 5, n_rows * 5))\n",
    "\n",
    "# Loop over each image, predict, and plot the result\n",
    "for i, image_path in enumerate(image_files):\n",
    "    # Load and preprocess the image\n",
    "    img = load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array / 255.0  # Normalize pixel values\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Add batch dimension\n",
    "\n",
    "    # Make predictions with your model\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_age = predictions[0].flatten()[0]\n",
    "    predicted_gender = predictions[1].flatten()[0]\n",
    "    pred_gender_label = \"Female\" if predicted_gender >= 0.5 else \"Male\"\n",
    "\n",
    "    # Plot the image with its predicted age and gender\n",
    "    plt.subplot(n_rows, n_cols, i + 1)\n",
    "    plt.imshow(load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH)))\n",
    "    plt.title(f\"Age: {predicted_age:.1f}\\nGender: {pred_gender_label}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model on test data\n",
    "image_path =  \"C:/Users/ziadt/Desktop/Projects/syed assignment/SyedAssign/Zezoo/test images/Screenshot 2025-03-02 170932.jpg\"\n",
    "img = load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "img_array = img_to_array(img)\n",
    "\n",
    "# Normalize the image\n",
    "img_array = img_array / 255.0\n",
    "\n",
    "# Add batch dimension\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "# Make predictions on some test samples\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "predicted_ages = predictions[0].flatten()\n",
    "predicted_genders = predictions[1].flatten()\n",
    "\n",
    "# Display the prediction for the single test image\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(img_array[0])\n",
    "pred_age = predicted_ages[0]\n",
    "pred_gender = predicted_genders[0]\n",
    "# For gender, apply a 0.5 threshold\n",
    "pred_gender_label = \"Female\" if pred_gender >= 0.5 else \"Male\"\n",
    "plt.title(f\"Predicted Age: {pred_age:.1f}\\nPredicted Gender: {pred_gender_label}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(filepath=\"C:/Users/ziadt/Desktop/Projects/syed assignment/Gen-Age-Predections/trained models/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV_masterclass_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
